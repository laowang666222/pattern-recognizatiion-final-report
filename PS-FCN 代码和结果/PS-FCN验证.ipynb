{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b2df4c7",
   "metadata": {},
   "source": [
    "## 1.导入依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff3c2267",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "731c2a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "from models import model_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809ceca4",
   "metadata": {},
   "source": [
    "## 2.创建实验参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d2bb379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from margs import myArg\n",
    "args=myArg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae3d5bc",
   "metadata": {},
   "source": [
    "## 3.导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d64baa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test Data] \t10 objs 96 lights. Root: data/datasets/DiLiGenT/pmsData\n",
      "Files for intensity: light_intensities.txt\n"
     ]
    }
   ],
   "source": [
    "from datasets.DiLiGenT_main import DiLiGenT_main\n",
    "test_set  = DiLiGenT_main(args, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e634716",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=args.test_batch,\n",
    "                                          num_workers=args.workers, pin_memory=args.cuda, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4f705ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/models/PS-FCN_B_S_32.pth.tar\n"
     ]
    }
   ],
   "source": [
    "print(args.retrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6847b93b",
   "metadata": {},
   "source": [
    "## 4.导入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bcb4a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Network Input] Color image as input\n",
      "[Network Input] Adding Light direction as input\n",
      "[Network Input] Input channel: 6\n",
      "Conv pad = 1\n",
      "Conv pad = 1\n",
      "Conv pad = 1\n",
      "Conv pad = 1\n",
      "Conv pad = 1\n",
      "Conv pad = 1\n",
      "Conv pad = 1\n",
      "Conv pad = 1\n"
     ]
    }
   ],
   "source": [
    "from models.PS_FCN_run import PS_FCN\n",
    "#输入图片数量和光线数量\n",
    "other = {'img_num': args.in_img_num, 'in_light': args.in_light}\n",
    "\n",
    "#得到输入的通道数，如果输入光照则为6通道，否则为3通道\n",
    "in_c = model_utils.getInputChanel(args)\n",
    "model = PS_FCN(args.fuse_type, args.use_BN, in_c, other)\n",
    "model = model.cuda()\n",
    "#导入预训练模型\n",
    "model_utils.loadCheckpoint(args.retrain, model, cuda=args.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfebc924",
   "metadata": {},
   "source": [
    "## 5.数据前向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd9683a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26 84  2 55 68 81 16 78 54 66 53 88 71 13  7 30 22 24 33  8 43 62  3 86\n",
      " 45 48  6 95 80 75 60 79]\n",
      "******************读取图片中*********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Desktop\\PS-FCN-master\\utils\\eval_utils.py:12: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen/native/IndexingUtils.h:28.)\n",
      "  ang_valid   = angular_map[mask.narrow(1, 0, 1).squeeze(1).byte()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40 31 46 59 78 74 65 44 80 85 62 27 91 77 32 56 39 10  2 38 54 58 19 90\n",
      " 95 35 33 48 84 67 55 36]\n",
      "******************读取图片中*********************\n",
      "[36 28 54 23 16 80  2 25 84 13 59 88 76 14  0 21  3 27 74 71 11 81 30 29\n",
      "  5 73 56 95 83  1 18 24]\n",
      "******************读取图片中*********************\n",
      "[61 23 94  9 25  6 79 71 57 64 15 77 58 70 81 45 78 89 42 93 12  8  4 76\n",
      " 34 17 68 82 40  5 13 31]\n",
      "******************读取图片中*********************\n",
      "[81 14 13 53 59 20 37 10 63  2 16 24 35 92 47 54 26 90 71 65 77 83 41 93\n",
      "  5 67 19 39 29 27  4 79]\n",
      "******************读取图片中*********************\n",
      "[42 57 48 32 67 22 10 20 17 28 35 34 54 24 39 60 50 83 12 66 91 46 23 13\n",
      " 59 68 37 84  6 92 26 40]\n",
      "******************读取图片中*********************\n",
      "[55 20 23 30  0 38 37 64 39 59 17 82 61 34 51 44 92 89 54 13 91 70 86 16\n",
      "  9 45 52 27 47 29 32 53]\n",
      "******************读取图片中*********************\n",
      "[20 82 77 73 37 15 52 36 26 33 13 22 95 12 59 40 11 71 18 93  2 17 62  5\n",
      " 45 91 58 30 51 49 89 27]\n",
      "******************读取图片中*********************\n",
      "[24 11  1 12 32 40 64 82 17  3 35 93 41 55 23 70 95 75 76 58 34 39 16 19\n",
      " 50 33 29 30 44 72 65 87]\n",
      "******************读取图片中*********************\n",
      "[ 6 46 26 79 28 38 64  3 20 45 66 73 82 84 42 25 41 21 31 39 23 69 36 17\n",
      " 43 57 71 61 14 32 78 80]\n",
      "******************读取图片中*********************\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "split='test'\n",
    "with torch.no_grad():\n",
    "    #loader就是DataLoade处理的数据，i是第几个obj，sample是第i个obj对应的item\n",
    "    for i, sample in enumerate(test_loader):\n",
    "        #这一步img的形状没变，就是改成tensor了\n",
    "        data = model_utils.parseData(args, sample, None, split)\n",
    "        #这个函数应该是得到输入的吧，直接传给模型了\n",
    "        input = model_utils.getInput(args, data)\n",
    "\n",
    "        #得到模型输出数据\n",
    "        out_var = model(input)\n",
    "        #计算准确率，应该是一个loss之类的\n",
    "        acc = eval_utils.calNormalAcc(data['tar'].data, out_var.data, data['m'].data) \n",
    "        \n",
    "        pred = (out_var.data + 1) / 2\n",
    "        masked_pred = pred * data['m'].data.expand_as(out_var.data)\n",
    "        #路径为当前模型下\n",
    "#         save_dir = os.path.join(os.path.join(os.path.dirname(args.retrain), 'run_model'), split)\n",
    "        save_name ='deep_norm{}.png'.format(i)\n",
    "        #保存图片\n",
    "        vutils.save_image(masked_pred, os.path.join(\"results\", save_name))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f860bd50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
